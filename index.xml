<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Datapio</title><link>https://datapio.co/</link><description>Recent content in Home on Datapio</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 24 Jun 2020 13:23:57 +0200</lastBuildDate><atom:link href="https://datapio.co/index.xml" rel="self" type="application/rss+xml"/><item><title>CI/CD reaches Alpha stage</title><link>https://datapio.co/news/cicd-reaches-alpha/</link><pubDate>Wed, 24 Jun 2020 13:23:57 +0200</pubDate><guid>https://datapio.co/news/cicd-reaches-alpha/</guid><description>As of today, the minimal functionalities of Datapio OpenCore, our CI/CD platform, are implemented.
Those functionalities includes:
project management concurrent pipeline scheduling pipeline as code, based on NodeJS What now? The roadmap for the next year will be:
improving the code and design quality full test and documentation coverage (free access for all our products) developing our cloud infrastructure, in order to provide this CI/CD platform, and many more features, in a complete SaaS solution looking for funding in order to improve our productivity and support</description></item><item><title>About</title><link>https://datapio.co/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/about/</guid><description>Why Datapio ? History lesson Docker:
developers can focus on writing business code packagers can focus on packaging applications operators can focus on deploying applications Kubernetes:
operators can describe the whole infrastructure in YAML orchestrate clusters and docker containers CI/CD:
packaging and deployment automated glue all aspects of a project&amp;rsquo;s lifecycle together Micro Services:
divide your application into decoupled services business code complexity decreased infrastructure complexity increased: service mesh auto discovery api gateway Event Sourcing:</description></item><item><title>Database System</title><link>https://datapio.co/docs/cloud/catalog/database-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/catalog/database-system/</guid><description>Currently integrated:
KubeDB Example --- apiVersion: datap.io/v1alpha1 kind: ClusterFeature metadata: name: database-system spec: kubedb: enabled: yes</description></item><item><title>Datapio OpenCore</title><link>https://datapio.co/docs/cloud/catalog/datapio-opencore/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/catalog/datapio-opencore/</guid><description>Example --- apiVersion: datap.io/v1alpha1 kind: ClusterFeature metadata: name: datapio-opencore spec: pipelinerunserver: enabled: yes project: enabled: yes</description></item><item><title>Explore Documentation</title><link>https://datapio.co/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/search/</guid><description>Search Results for &amp;laquo; &amp;raquo; const do_search = async () = { const params = new URLSearchParams(window.location.search) if (params.has('query')) { const index = await $.getJSON("/search-index.json") const data = { query: $('#search-query'), target: $('#search-lunr'), index: elasticlunr.Index.load(index) } let results try { data.query.text(params.get('query')) results = data.index.search(params.get('query'), { bool: 'AND' }) } catch (err) { results = [] } results.forEach(match = { const item = match.</description></item><item><title>Ingress System</title><link>https://datapio.co/docs/cloud/catalog/ingress-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/catalog/ingress-system/</guid><description>Currently integrated:
NGinX Ingress Controller Example --- apiVersion: datap.io/v1alpha1 kind: ClusterFeature metadata: name: ingress-system spec: nginx: enabled: yes</description></item><item><title>Manage projects</title><link>https://datapio.co/docs/cicd/manage-projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cicd/manage-projects/</guid><description>Overview Datapio provides the resource Project, which defines a set of webhooks. Each webhook has distinct concurrency settings, and a distinct PipelineRunServer will be deployed for each.
Alongside the PipelineRunServer, will be deployed Tekton resources to configure the webhook and create the continuous pipeline.
The continuous pipeline is composed of:
1 PersistentVolumeClaim as workspace 2 Task: checkout the repository from the SCM inside the workspace run the pipeline code from the repository inside the workspace Example --- apiVersion: datap.</description></item><item><title>Managed Kubernetes</title><link>https://datapio.co/docs/cloud/managed-k8s/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/managed-k8s/</guid><description>Overview The creation of a resource Cluster will trigger the deployment and provisionning of:
the Kubernetes cluster&amp;rsquo;s control plane, using OneInfra the worker nodes using common Cloud APIs Example --- apiVersion: datap.io/v1alpha1 kind: Cluster metadata: name: my-cluster namespace: default spec: controlPlane: replicas: 3 workers: - cpu: 3GHz memory: 16GB - cpu: 3GHz memory: 16GB - cpu: 3GHz memory: 16GB NB: This example is only a draft.</description></item><item><title>Managed Services</title><link>https://datapio.co/docs/cloud/managed-services/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/managed-services/</guid><description>Overview Managed services such as a database, secret storages, or load balancers can be complex to manage on your own. Datapio provides the deployment of various Kubernetes operators in order to handle the complexity.
The Catalog Operator allows you to enable in your cluster such managed services through ClusterFeature resources. The creation of those resources will trigger the deployment of the corresponding operators to a dedicated namespace.</description></item><item><title>Messaging System</title><link>https://datapio.co/docs/cloud/catalog/mq-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/catalog/mq-system/</guid><description>Currently integrated:
RabbitMQ Operator Example --- apiVersion: datap.io/v1alpha1 kind: ClusterFeature metadata: name: mq-system spec: rabbitmq: enabled: yes</description></item><item><title>Pipeline As Code</title><link>https://datapio.co/docs/cicd/pipeline-as-code/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cicd/pipeline-as-code/</guid><description>Overview Datapio relies on NodeJS to run the pipeline. Its code is executed in a sandboxed environment.
A pipeline SHOULD declare:
a name a set of tools used by the pipeline to interact with other softwares such as: Docker Tekton Vault Helm Git &amp;hellip; an environment (constructed using the set of tools) a list of stages, representing the steps of your pipeline Creating your pipeline The pipeline&amp;rsquo;s entrypoint is located (relative to the root of your repository) by default at .</description></item><item><title>Pipeline Scheduling Model</title><link>https://datapio.co/docs/cicd/pipeline-scheduling-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cicd/pipeline-scheduling-model/</guid><description>Overview With Tekton, you can define your pipelines as Pipeline resources, and trigger their execution with a PipelineRun.
Datapio introduces the PipelineRunServer and PipelineRunRequest resources.
The server provides the concurrency settings, such as:
maximum number of concurrent PipelineRun maximum number of completed PipelineRun to keep The request defines:
a reference to the server that must process this request a reference to the pipeline that must be run a listing of all the resources that must be created for the PipelineRun (and deleted with it) Once a PipelineRunRequest is added to the cluster, the operator immediatly sends the request to a RabbitMQ queue, consumed by the server&amp;rsquo;s workers.</description></item><item><title>Pipeline System</title><link>https://datapio.co/docs/cloud/catalog/pipeline-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/catalog/pipeline-system/</guid><description>Currently integrated:
TektonCD Example --- apiVersion: datap.io/v1alpha1 kind: ClusterFeature metadata: name: pipeline-system spec: tekton: enabled: yes</description></item><item><title>Secret System</title><link>https://datapio.co/docs/cloud/catalog/secret-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cloud/catalog/secret-system/</guid><description>Currently integrated:
Cert Manager KubeVault Example --- apiVersion: datap.io/v1alpha1 kind: ClusterFeature metadata: name: secret-system spec: certmanager: enabled: yes kubevault: enabled: yes</description></item></channel></rss>