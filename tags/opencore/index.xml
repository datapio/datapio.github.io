<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>opencore on Datapio</title><link>https://datapio.co/tags/opencore/</link><description>Recent content in opencore on Datapio</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 24 Jun 2020 13:23:57 +0200</lastBuildDate><atom:link href="https://datapio.co/tags/opencore/index.xml" rel="self" type="application/rss+xml"/><item><title>CI/CD reaches Alpha stage</title><link>https://datapio.co/news/cicd-reaches-alpha/</link><pubDate>Wed, 24 Jun 2020 13:23:57 +0200</pubDate><guid>https://datapio.co/news/cicd-reaches-alpha/</guid><description>As of today, the minimal functionalities of Datapio OpenCore, our CI/CD platform, are implemented.
Those functionalities includes:
project management concurrent pipeline scheduling pipeline as code, based on NodeJS What now? The roadmap for the next year will be:
improving the code and design quality full test and documentation coverage (free access for all our products) developing our cloud infrastructure, in order to provide this CI/CD platform, and many more features, in a complete SaaS solution looking for funding in order to improve our productivity and support</description></item><item><title>Manage projects</title><link>https://datapio.co/docs/cicd/manage-projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cicd/manage-projects/</guid><description>Overview Datapio provides the resource Project, which defines a set of webhooks. Each webhook has distinct concurrency settings, and a distinct PipelineRunServer will be deployed for each.
Alongside the PipelineRunServer, will be deployed Tekton resources to configure the webhook and create the continuous pipeline.
The continuous pipeline is composed of:
1 PersistentVolumeClaim as workspace 2 Task: checkout the repository from the SCM inside the workspace run the pipeline code from the repository inside the workspace Example --- apiVersion: datap.</description></item><item><title>Pipeline As Code</title><link>https://datapio.co/docs/cicd/pipeline-as-code/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cicd/pipeline-as-code/</guid><description>Overview Datapio relies on NodeJS to run the pipeline. Its code is executed in a sandboxed environment.
A pipeline SHOULD declare:
a name a set of tools used by the pipeline to interact with other softwares such as: Docker Tekton Vault Helm Git &amp;hellip; an environment (constructed using the set of tools) a list of stages, representing the steps of your pipeline Creating your pipeline The pipeline&amp;rsquo;s entrypoint is located (relative to the root of your repository) by default at .</description></item><item><title>Pipeline Scheduling Model</title><link>https://datapio.co/docs/cicd/pipeline-scheduling-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://datapio.co/docs/cicd/pipeline-scheduling-model/</guid><description>Overview With Tekton, you can define your pipelines as Pipeline resources, and trigger their execution with a PipelineRun.
Datapio introduces the PipelineRunServer and PipelineRunRequest resources.
The server provides the concurrency settings, such as:
maximum number of concurrent PipelineRun maximum number of completed PipelineRun to keep The request defines:
a reference to the server that must process this request a reference to the pipeline that must be run a listing of all the resources that must be created for the PipelineRun (and deleted with it) Once a PipelineRunRequest is added to the cluster, the operator immediatly sends the request to a RabbitMQ queue, consumed by the server&amp;rsquo;s workers.</description></item></channel></rss>